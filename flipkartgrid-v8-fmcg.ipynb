{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics\n!pip install opencv-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO(\"yolov8n.yaml\")  # build a new model from YAML\nmodel = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\nmodel = YOLO(\"yolov8n.yaml\").load(\"yolov8n.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T01:35:41.767418Z","iopub.execute_input":"2024-10-18T01:35:41.768241Z","iopub.status.idle":"2024-10-18T01:35:42.137856Z","shell.execute_reply.started":"2024-10-18T01:35:41.768198Z","shell.execute_reply":"2024-10-18T01:35:42.137068Z"}},"outputs":[{"name":"stdout","text":"Transferred 319/391 items from pretrained weights\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -U ipywidgets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.train(data=\"/kaggle/input/fmcg-product-dataset/data.yaml\",\n                      epochs=10, \n                      imgsz=640, \n                      # device=[0, 1],\n                      verbose=True,\n                      project=\"model_trained\",\n                      name=\"initial_testing\",\n                      batch=0.8,\n                      resume=True\n                      )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T01:37:00.469317Z","iopub.execute_input":"2024-10-18T01:37:00.469858Z","iopub.status.idle":"2024-10-18T02:28:24.558881Z","shell.execute_reply.started":"2024-10-18T01:37:00.469816Z","shell.execute_reply":"2024-10-18T02:28:24.557937Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.15 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/kaggle/input/fmcg-product-dataset/data.yaml, epochs=10, time=None, patience=100, batch=0.8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=model_trained, name=initial_testing, exist_ok=False, pretrained=yolov8n.pt, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=None, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=model_trained/initial_testing\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=25\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    435547  ultralytics.nn.modules.head.Detect           [25, [64, 128, 256]]          \nYOLOv8n summary: 249 layers, 2,695,083 parameters, 2,695,067 gradients, 7.0 GFLOPs\n\nTransferred 340/391 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir model_trained/initial_testing', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114059277777718, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb16f533f6dc4420bb2ff80c0ed4240e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241018_013734-r2t72v0c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/multi-head/model_trained/runs/r2t72v0c' target=\"_blank\">initial_testing</a></strong> to <a href='https://wandb.ai/multi-head/model_trained' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/multi-head/model_trained' target=\"_blank\">https://wandb.ai/multi-head/model_trained</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/multi-head/model_trained/runs/r2t72v0c' target=\"_blank\">https://wandb.ai/multi-head/model_trained/runs/r2t72v0c</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 89.4MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 80.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.12G reserved, 0.06G allocated, 15.71G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     2695083       6.968         0.191         42.69         128.7        (1, 3, 640, 640)                    list\n     2695083       13.94         0.319         23.99         49.18        (2, 3, 640, 640)                    list\n     2695083       27.87         0.621         29.56         108.5        (4, 3, 640, 640)                    list\n     2695083       55.74         1.139         26.55         41.44        (8, 3, 640, 640)                    list\n     2695083       111.5         2.372         36.25         65.93       (16, 3, 640, 640)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 86 for CUDA:0 12.69G/15.89G (80%) ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/fmcg-product-dataset/train/labels... 29673 images, 6 backgrounds, 0 corrupt: 100%|██████████| 29673/29673 [01:19<00:00, 374.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/fmcg-product-dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/fmcg-product-dataset/valid/labels... 2815 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2815/2815 [00:07<00:00, 368.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/fmcg-product-dataset/valid is not writeable, cache not saved.\nPlotting labels to model_trained/initial_testing/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000345, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0006718750000000001), 69 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mmodel_trained/initial_testing\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      11.7G     0.7722      3.606      1.368          3        640: 100%|██████████| 346/346 [04:33<00:00,  1.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:16<00:00,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.942      0.936      0.977      0.749\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/10      11.6G     0.6989       1.35       1.24          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816       0.98      0.974      0.993      0.776\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/10      11.6G     0.6479     0.8173      1.196          3        640: 100%|██████████| 346/346 [04:30<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816       0.99      0.975      0.994      0.843\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/10      11.6G     0.6048     0.5457      1.162          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.991       0.99      0.993      0.805\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/10      11.6G     0.5728     0.4159      1.136          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:14<00:00,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.995      0.993      0.995      0.845\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/10      11.6G     0.5475     0.3474      1.116          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.996      0.995      0.994      0.858\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/10      11.6G     0.5255     0.3082      1.098          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.997      0.996      0.995      0.867\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/10      11.6G     0.5089     0.2827      1.085          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.997      0.996      0.995      0.889\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/10      11.6G     0.4872     0.2623      1.071          3        640: 100%|██████████| 346/346 [04:30<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.998      0.997      0.995      0.899\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/10      11.6G     0.4711     0.2467       1.06          3        640: 100%|██████████| 346/346 [04:29<00:00,  1.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.998      0.997      0.995      0.904\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n10 epochs completed in 0.798 hours.\nOptimizer stripped from model_trained/initial_testing/weights/last.pt, 5.6MB\nOptimizer stripped from model_trained/initial_testing/weights/best.pt, 5.6MB\n\nValidating model_trained/initial_testing/weights/best.pt...\nWARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\nUltralytics 8.3.15 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv8n summary (fused): 186 layers, 2,689,243 parameters, 0 gradients, 6.8 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:18<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2815       2816      0.998      0.997      0.995      0.904\nBisconni Chocolate Chip Cookies 46.8gm        118        118      0.999          1      0.995      0.934\n   Coca Cola Can 250ml        120        121      0.998      0.992      0.995      0.909\nColgate Maximum Cavity Protection 75gm        130        130      0.999          1      0.995      0.893\n           Fanta 500ml        117        117      0.999          1      0.995      0.937\nFresher Guava Nectar 500ml         94         94      0.998          1      0.995      0.929\nFruita Vitals Red Grapes 200ml         95         95      0.998          1      0.995      0.954\n   Islamabad Tea 238gm        103        103      0.998          1      0.995      0.916\nKolson Slanty Jalapeno 18gm        127        127          1          1      0.995      0.857\nKurkure Chutney Chaska 62gm        115        115      0.998          1      0.995      0.931\n LU Candi Biscuit 60gm        120        120      0.992       0.99      0.995      0.858\n  LU Oreo Biscuit 19gm        106        106      0.998          1      0.995      0.906\nLU Prince Biscuit 55.2gm        124        124          1      0.992      0.995      0.852\n      Lays Masala 34gm        122        122      0.998          1      0.995      0.942\nLays Wavy Mexican Chili 34gm        118        118      0.999          1      0.995      0.907\nLifebuoy Total Protect Soap 96gm        117        117      0.997          1      0.995      0.948\nLipton Yellow Label Tea 95gm        112        112      0.991      0.991      0.993      0.853\nMeezan Ultra Rich Tea 190gm        123        123      0.999          1      0.995      0.903\nPeek Freans Sooper Biscuit 13.2gm         90         90      0.998          1      0.995      0.916\nSafeguard Bar Soap Pure White 175gm         70         70          1      0.973      0.995      0.835\n    Shezan Apple 250ml        130        130      0.997      0.992      0.995      0.908\nSunsilk Shampoo Soft - Smooth 160ml         89         89      0.998          1      0.995      0.942\n  Super Crisp BBQ 30gm        120        120      0.999          1      0.995      0.903\n      Supreme Tea 95gm        120        120      0.998          1      0.995      0.892\n    Tapal Danedar 95gm        128        128      0.999          1      0.995      0.847\nVaseline Healthy White Lotion 100ml        107        107      0.998          1      0.995      0.919\nSpeed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 1.2ms postprocess per image\nResults saved to \u001b[1mmodel_trained/initial_testing\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='14.657 MB of 14.657 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2dfe928c386424d9ec7f55e3952fcd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▃▆█▇▆▅▄▃▂▁</td></tr><tr><td>lr/pg1</td><td>▃▆█▇▆▅▄▃▂▁</td></tr><tr><td>lr/pg2</td><td>▃▆█▇▆▅▄▃▂▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▇█▇██████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▂▅▄▅▆▆▇██</td></tr><tr><td>metrics/precision(B)</td><td>▁▆▇▇██████</td></tr><tr><td>metrics/recall(B)</td><td>▁▅▅▇██████</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train/cls_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>val/box_loss</td><td>██▄▇▄▄▃▂▁▁</td></tr><tr><td>val/cls_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▇▄▆▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.99492</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.90372</td></tr><tr><td>metrics/precision(B)</td><td>0.99794</td></tr><tr><td>metrics/recall(B)</td><td>0.99719</td></tr><tr><td>model/GFLOPs</td><td>6.968</td></tr><tr><td>model/parameters</td><td>2695083</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.885</td></tr><tr><td>train/box_loss</td><td>0.47113</td></tr><tr><td>train/cls_loss</td><td>0.24674</td></tr><tr><td>train/dfl_loss</td><td>1.05986</td></tr><tr><td>val/box_loss</td><td>0.46928</td></tr><tr><td>val/cls_loss</td><td>0.24233</td></tr><tr><td>val/dfl_loss</td><td>0.95954</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">initial_testing</strong> at: <a href='https://wandb.ai/multi-head/model_trained/runs/r2t72v0c' target=\"_blank\">https://wandb.ai/multi-head/model_trained/runs/r2t72v0c</a><br/> View project at: <a href='https://wandb.ai/multi-head/model_trained' target=\"_blank\">https://wandb.ai/multi-head/model_trained</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 21 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241018_013734-r2t72v0c/logs</code>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"!zip -r output.zip /kaggle/working/model_trained/initial_testing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T02:29:04.857650Z","iopub.execute_input":"2024-10-18T02:29:04.858366Z","iopub.status.idle":"2024-10-18T02:29:06.775692Z","shell.execute_reply.started":"2024-10-18T02:29:04.858307Z","shell.execute_reply":"2024-10-18T02:29:06.774534Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/model_trained/initial_testing/ (stored 0%)\n  adding: kaggle/working/model_trained/initial_testing/events.out.tfevents.1729215436.655cd4f9acb2.30.0 (deflated 93%)\n  adding: kaggle/working/model_trained/initial_testing/PR_curve.png (deflated 28%)\n  adding: kaggle/working/model_trained/initial_testing/labels.jpg (deflated 21%)\n  adding: kaggle/working/model_trained/initial_testing/train_batch2.jpg (deflated 7%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch1_labels.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/results.png (deflated 8%)\n  adding: kaggle/working/model_trained/initial_testing/R_curve.png (deflated 15%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch0_labels.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/results.csv (deflated 59%)\n  adding: kaggle/working/model_trained/initial_testing/weights/ (stored 0%)\n  adding: kaggle/working/model_trained/initial_testing/weights/best.pt (deflated 10%)\n  adding: kaggle/working/model_trained/initial_testing/weights/last.pt (deflated 10%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch2_pred.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch1_pred.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch2_labels.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/F1_curve.png (deflated 15%)\n  adding: kaggle/working/model_trained/initial_testing/args.yaml (deflated 53%)\n  adding: kaggle/working/model_trained/initial_testing/confusion_matrix_normalized.png (deflated 14%)\n  adding: kaggle/working/model_trained/initial_testing/train_batch1.jpg (deflated 9%)\n  adding: kaggle/working/model_trained/initial_testing/train_batch0.jpg (deflated 6%)\n  adding: kaggle/working/model_trained/initial_testing/P_curve.png (deflated 25%)\n  adding: kaggle/working/model_trained/initial_testing/confusion_matrix.png (deflated 14%)\n  adding: kaggle/working/model_trained/initial_testing/val_batch0_pred.jpg (deflated 5%)\n  adding: kaggle/working/model_trained/initial_testing/labels_correlogram.jpg (deflated 34%)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(r'output.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T02:29:31.118190Z","iopub.execute_input":"2024-10-18T02:29:31.118867Z","iopub.status.idle":"2024-10-18T02:29:31.125236Z","shell.execute_reply.started":"2024-10-18T02:29:31.118825Z","shell.execute_reply":"2024-10-18T02:29:31.124242Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/output.zip","text/html":"<a href='output.zip' target='_blank'>output.zip</a><br>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}